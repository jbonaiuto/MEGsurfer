{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from megsurfer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemispheres=['lh','rh']\n",
    "fs_subjects_dir=os.getenv('SUBJECTS_DIR')\n",
    "\n",
    "def postprocess_freesurfer_surfaces(subj_id,\n",
    "                                    out_dir,\n",
    "                                    out_fname,\n",
    "                                    n_surfaces=2, \n",
    "                                    ds_factor=0.1, \n",
    "                                    orientation='link', \n",
    "                                    remove_deep=True):\n",
    "\n",
    "    fs_subject_dir=os.path.join(fs_subjects_dir, subj_id)\n",
    "\n",
    "    subject_out_dir=os.path.join(out_dir, subj_id)\n",
    "    layers = np.linspace(1, 0, n_surfaces)\n",
    "\n",
    "    \n",
    "    ## Create intermediate surfaces if needed\n",
    "    layer_names=[]\n",
    "    for l, layer in enumerate(layers):\n",
    "        if layer==1:\n",
    "            layer_names.append('pial')\n",
    "        elif layer>0 and layer<1:\n",
    "            layer_name='{:.3f}'.format(layer)\n",
    "            layer_names.append(layer_name)\n",
    "            for hemi in hemispheres:\n",
    "                wm_file=os.path.join(fs_subject_dir, 'surf', '{}.white'.format(hemi))\n",
    "                out_file=os.path.join(fs_subject_dir, 'surf', '{}.{}'.format(hemi,layer_name))\n",
    "                cmd=['mris_expand','-thickness',wm_file,'{}'.format(layer),out_file]\n",
    "                print(' '.join(cmd))\n",
    "                subprocess.run(cmd)\n",
    "        elif layer==0:\n",
    "            layer_names.append('white')\n",
    "\n",
    "            \n",
    "    ## Compute RAS offset\n",
    "    # Define the path to the MRI file\n",
    "    ras_off_file = os.path.join(fs_subject_dir, 'mri', 'orig.mgz')\n",
    "\n",
    "    # Execute the shell command to get RAS offset\n",
    "    command = f\"mri_info --cras {ras_off_file}\"\n",
    "    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    out, err = process.communicate()\n",
    "\n",
    "    # Parse the output\n",
    "    cols = out.decode().split()\n",
    "    ras_offset = np.array([float(cols[0]), float(cols[1]), float(cols[2])])\n",
    "\n",
    "    # Print the result\n",
    "    print(ras_offset)\n",
    "\n",
    "    \n",
    "    ## Convert to gifti, adjut for RAS offset, and remove deep vertices\n",
    "    for layer_name in layer_names:\n",
    "        for hemi in hemispheres:\n",
    "            # Construct the original and new file names\n",
    "            orig_name = os.path.join(fs_subject_dir, 'surf', f'{hemi}.{layer_name}')\n",
    "            new_name = os.path.join(subject_out_dir, f'{hemi}.{layer_name}.gii')\n",
    "\n",
    "            # Convert the surface file to Gifti format\n",
    "            subprocess.run(['mris_convert', orig_name, new_name])\n",
    "\n",
    "            # Load the Gifti file\n",
    "            g = nib.load(new_name)\n",
    "\n",
    "            # Set transformation matrix to identity\n",
    "            g.affine = np.eye(4)\n",
    "\n",
    "            # Adjust for RAS offset\n",
    "            n_vertices=0\n",
    "            for da in g.darrays:\n",
    "                if da.intent == nib.nifti1.intent_codes['NIFTI_INTENT_POINTSET']:\n",
    "                    da.data += ras_offset\n",
    "                    n_vertices= da.data.shape[0]\n",
    "\n",
    "            annotation = os.path.join(fs_subject_dir, 'label', f'{hemi}.aparc.annot')\n",
    "            label, ctab, names = nib.freesurfer.read_annot(annotation)\n",
    "\n",
    "            # Remove vertices created by cutting the hemispheres\n",
    "            if remove_deep:\n",
    "                vertices_to_remove=[]\n",
    "                for vtx in range(n_vertices):\n",
    "                    if label[vtx] > 0:\n",
    "                        region = names[label[vtx]]\n",
    "                        if region == 'unknown':\n",
    "                            vertices_to_remove.append(vtx)\n",
    "                    else:\n",
    "                        vertices_to_remove.append(vtx)\n",
    "                g=remove_vertices(g, np.array(vertices_to_remove))\n",
    "\n",
    "            # Save the modified Gifti file\n",
    "            nib.save(g, new_name)\n",
    "\n",
    "                        \n",
    "    ## Combine hemispheres\n",
    "    for layer_name in layer_names:\n",
    "        # Load left and right hemisphere surfaces\n",
    "        lh_fname = os.path.join(subject_out_dir, f'lh.{layer_name}.gii')\n",
    "        lh = nib.load(lh_fname)\n",
    "        rh_fname = os.path.join(subject_out_dir, f'rh.{layer_name}.gii')\n",
    "        rh = nib.load(rh_fname)\n",
    "\n",
    "        # Combine the surfaces\n",
    "        combined=combine_surfaces([lh, rh])    \n",
    "        combined_fname = os.path.join(subject_out_dir, f'{layer_name}.gii')\n",
    "        nib.save(combined, combined_fname)\n",
    "\n",
    "        \n",
    "    ## Downsample surfaces at the same time\n",
    "    # Get list of surfaces\n",
    "    in_surfs = []\n",
    "    for layer_name in layer_names:\n",
    "        in_surf_fname = os.path.join(subject_out_dir, f'{layer_name}.gii')\n",
    "        in_surf = nib.load(in_surf_fname)\n",
    "        in_surfs.append(in_surf)\n",
    "\n",
    "    # Downsample multiple surfaces\n",
    "    out_surfs = downsample_multiple_surfaces(in_surfs, ds_factor)\n",
    "    for layer_name, out_surf in zip(layer_names, out_surfs):\n",
    "        out_surf_path = os.path.join(subject_out_dir, f'{layer_name}.ds.gii')\n",
    "        nib.save(out_surf, out_surf_path)\n",
    "        \n",
    "    \n",
    "    ## Compute link vectors\n",
    "    # Load downsampled pial and white surfaces\n",
    "    pial_surf = nib.load(os.path.join(subject_out_dir, 'pial.ds.gii'))\n",
    "    white_surf = nib.load(os.path.join(subject_out_dir, 'white.ds.gii'))\n",
    "\n",
    "    # Extract vertices\n",
    "    pial_vertices = pial_surf.darrays[0].data\n",
    "    white_vertices = white_surf.darrays[0].data\n",
    "\n",
    "    # Check for equal number of vertices\n",
    "    if pial_vertices.shape[0] != white_vertices.shape[0]:\n",
    "        raise ValueError(\"Pial and white surfaces must have the same number of vertices\")\n",
    "\n",
    "    # Compute link vectors (normals)\n",
    "    link_vectors = white_vertices - pial_vertices\n",
    "\n",
    "    for layer_name in layer_names:\n",
    "        in_surf_path = os.path.join(subject_out_dir, f'{layer_name}.ds.gii')        \n",
    "        surf = nib.load(in_surf_path)\n",
    "\n",
    "        # Set these link vectors as the normals for the downsampled surface\n",
    "        surf.add_gifti_data_array(nib.gifti.GiftiDataArray(data=link_vectors,\n",
    "                                                           intent=nib.nifti1.intent_codes['NIFTI_INTENT_VECTOR']))\n",
    "\n",
    "        # Save the modified downsampled surface with link vectors as normals\n",
    "        out_surf_path = os.path.join(subject_out_dir, f'{layer_name}.ds.link_vector.gii')\n",
    "        nib.save(surf, out_surf_path)\n",
    "        \n",
    "        \n",
    "    ## Combine layers\n",
    "    all_surfs=[]\n",
    "    for layer_name in layer_names:\n",
    "        surf_path = os.path.join(subject_out_dir, f'{layer_name}.ds.link_vector.gii')\n",
    "        surf = nib.load(surf_path)\n",
    "        all_surfs.append(surf)\n",
    "\n",
    "    combined = combine_surfaces(all_surfs)\n",
    "    nib.save(combined, os.path.join(subject_out_dir, out_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mris_expand -thickness /home/bonaiuto/Dropbox/Projects/software/MEGsurfer/python/test_data/fs/sub-104/surf/lh.white 0.9 /home/bonaiuto/Dropbox/Projects/software/MEGsurfer/python/test_data/fs/sub-104/surf/lh.0.900\n",
      "using distance as a % of thickness\n",
      "expanding surface /home/bonaiuto/Dropbox/Projects/software/MEGsurfer/python/test_data/fs/sub-104/surf/lh.white by 90.0% of thickness and writing it to /home/bonaiuto/Dropbox/Projects/software/MEGsurfer/python/test_data/fs/sub-104/surf/lh.0.900\n",
      "reading thickness...\n",
      "-01: dt=0.0000, 0 negative triangles\n",
      "ending sse = 9707.569352\n",
      "nrounds = 6\n",
      "step 27 of 432     "
     ]
    }
   ],
   "source": [
    "postprocess_freesurfer_surfaces('sub-104',                                \n",
    "                                './test_output',\n",
    "                                'multilayer.11.ds.link_vector.gii',\n",
    "                                n_surfaces=11, \n",
    "                                ds_factor=0.1, \n",
    "                                orientation='link', \n",
    "                                remove_deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MEGsurfer",
   "language": "python",
   "name": "megsurfer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
